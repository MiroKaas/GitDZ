[student1669_3@bigdataanalytics-worker-3 ~]$ export SPARK_KAFKA_VERSION=0.10
[student1669_3@bigdataanalytics-worker-3 ~]$ /opt/spark-2.4.8/bin/pyspark --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5
Python 2.7.5 (default, Nov 16 2020, 22:23:17) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
Ivy Default Cache set to: /home/student1669_3/.ivy2/cache
The jars for the packages stored in: /home/student1669_3/.ivy2/jars
:: loading settings :: url = jar:file:/opt/spark-2.4.8/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
org.apache.spark#spark-sql-kafka-0-10_2.11 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-cdb8a921-8d7a-4cf0-a15a-f57fe55ac441;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.11;2.4.5 in central
	found org.apache.kafka#kafka-clients;2.0.0 in central
	found org.lz4#lz4-java;1.4.0 in central
	found org.xerial.snappy#snappy-java;1.1.7.3 in central
	found org.slf4j#slf4j-api;1.7.16 in central
	found org.spark-project.spark#unused;1.0.0 in central
:: resolution report :: resolve 282ms :: artifacts dl 5ms
	:: modules in use:
	org.apache.kafka#kafka-clients;2.0.0 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.11;2.4.5 from central in [default]
	org.lz4#lz4-java;1.4.0 from central in [default]
	org.slf4j#slf4j-api;1.7.16 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.3 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   6   |   0   |   0   |   0   ||   6   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-cdb8a921-8d7a-4cf0-a15a-f57fe55ac441
	confs: [default]
	0 artifacts copied, 6 already retrieved (0kB/5ms)
22/09/06 13:19:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 2.4.8
      /_/

Using Python version 2.7.5 (default, Nov 16 2020 22:23:17)
SparkSession available as 'spark'.
>>> from pyspark.sql import functions as F
>>> from pyspark.sql.types import StructType, StringType, FloatType
>>> kafka_brokers = "bigdataanalytics-worker-3:6667"
>>> Создаем стрим, читаем из Кафки.
  File "<stdin>", line 1
    Создаем стрим, читаем из Кафки.
    ^
SyntaxError: invalid syntax
>>> 
>>> ```python
  File "<stdin>", line 1
    ```python
            ^
SyntaxError: invalid syntax
>>> raw_data = spark.readStream. \
...     format("kafka"). \
...     option("kafka.bootstrap.servers", kafka_brokers). \
...     option("subscribe", "timofeeva_iris"). \
...     option("startingOffsets", "earliest"). \
...     option("maxOffsetsPerTrigger", "5"). \
...     load()
>>> 
>>> schema = StructType() \
...     .add("sepalLength", FloatType()) \
...     .add("sepalWidth", FloatType()) \
...     .add("petalLength", FloatType()) \
...     .add("petalWidth", FloatType()) \
...     .add("species", StringType())
>>> def console_output(df, freq):
...     return df.writeStream \
...         .format("console") \
...         .trigger(processingTime='%s seconds' % freq ) \
...         .options(truncate=False) \
...         .start()
... 
>>> out = console_output(raw_data, 5)
22/09/06 13:27:50 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
-------------------------------------------                                     
Batch: 0
-------------------------------------------
+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------+------+-----------------------+-------------+
|key |value                                                                                                                                                                                                                                                                                                              |topic         |partition|offset|timestamp              |timestampType|
+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------+------+-----------------------+-------------+
|null|[5B]                                                                                                                                                                                                                                                                                                               |timofeeva_iris|0        |0     |2022-08-29 12:29:03.85 |0            |
|null|[20 20 7B 22 73 65 70 61 6C 4C 65 6E 67 74 68 22 3A 20 35 2E 31 2C 20 22 73 65 70 61 6C 57 69 64 74 68 22 3A 20 33 2E 35 2C 20 22 70 65 74 61 6C 4C 65 6E 67 74 68 22 3A 20 31 2E 34 2C 20 22 70 65 74 61 6C 57 69 64 74 68 22 3A 20 30 2E 32 2C 20 22 73 70 65 63 69 65 73 22 3A 20 22 73 65 74 6F 73 61 22 7D 2C]|timofeeva_iris|0        |1     |2022-08-29 12:29:03.858|0            |
|null|[20 20 7B 22 73 65 70 61 6C 4C 65 6E 67 74 68 22 3A 20 34 2E 39 2C 20 22 73 65 70 61 6C 57 69 64 74 68 22 3A 20 33 2E 30 2C 20 22 70 65 74 61 6C 4C 65 6E 67 74 68 22 3A 20 31 2E 34 2C 20 22 70 65 74 61 6C 57 69 64 74 68 22 3A 20 30 2E 32 2C 20 22 73 70 65 63 69 65 73 22 3A 20 22 73 65 74 6F 73 61 22 7D 2C]|timofeeva_iris|0        |2     |2022-08-29 12:29:03.858|0            |
|null|[20 20 7B 22 73 65 70 61 6C 4C 65 6E 67 74 68 22 3A 20 34 2E 37 2C 20 22 73 65 70 61 6C 57 69 64 74 68 22 3A 20 33 2E 32 2C 20 22 70 65 74 61 6C 4C 65 6E 67 74 68 22 3A 20 31 2E 33 2C 20 22 70 65 74 61 6C 57 69 64 74 68 22 3A 20 30 2E 32 2C 20 22 73 70 65 63 69 65 73 22 3A 20 22 73 65 74 6F 73 61 22 7D 2C]|timofeeva_iris|0        |3     |2022-08-29 12:29:03.858|0            |
|null|[20 20 7B 22 73 65 70 61 6C 4C 65 6E 67 74 68 22 3A 20 34 2E 36 2C 20 22 73 65 70 61 6C 57 69 64 74 68 22 3A 20 33 2E 31 2C 20 22 70 65 74 61 6C 4C 65 6E 67 74 68 22 3A 20 31 2E 35 2C 20 22 70 65 74 61 6C 57 69 64 74 68 22 3A 20 30 2E 32 2C 20 22 73 70 65 63 69 65 73 22 3A 20 22 73 65 74 6F 73 61 22 7D 2C]|timofeeva_iris|0        |4     |2022-08-29 12:29:03.858|0            |
+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------+------+-----------------------+-------------+

-------------------------------------------
Batch: 1
-------------------------------------------
+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------+------+-----------------------+-------------+
|key |value                                                                                                                                                                                                                                                                                                              |topic         |partition|offset|timestamp              |timestampType|
+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------+------+-----------------------+-------------+
|null|[20 20 7B 22 73 65 70 61 6C 4C 65 6E 67 74 68 22 3A 20 35 2E 30 2C 20 22 73 65 70 61 6C 57 69 64 74 68 22 3A 20 33 2E 36 2C 20 22 70 65 74 61 6C 4C 65 6E 67 74 68 22 3A 20 31 2E 34 2C 20 22 70 65 74 61 6C 57 69 64 74 68 22 3A 20 30 2E 32 2C 20 22 73 70 65 63 69 65 73 22 3A 20 22 73 65 74 6F 73 61 22 7D 2C]|timofeeva_iris|0        |5     |2022-08-29 12:29:03.858|0            |
|null|[20 20 7B 22 73 65 70 61 6C 4C 65 6E 67 74 68 22 3A 20 35 2E 34 2C 20 22 73 65 70 61 6C 57 69 64 74 68 22 3A 20 33 2E 39 2C 20 22 70 65 74 61 6C 4C 65 6E 67 74 68 22 3A 20 31 2E 37 2C 20 22 70 65 74 61 6C 57 69 64 74 68 22 3A 20 30 2E 34 2C 20 22 73 70 65 63 69 65 73 22 3A 20 22 73 65 74 6F 73 61 22 7D 2C]|timofeeva_iris|0        |6     |2022-08-29 12:29:03.858|0            |
|null|[20 20 7B 22 73 65 70 61 6C 4C 65 6E 67 74 68 22 3A 20 34 2E 36 2C 20 22 73 65 70 61 6C 57 69 64 74 68 22 3A 20 33 2E 34 2C 20 22 70 65 74 61 6C 4C 65 6E 67 74 68 22 3A 20 31 2E 34 2C 20 22 70 65 74 61 6C 57 69 64 74 68 22 3A 20 30 2E 33 2C 20 22 73 70 65 63 69 65 73 22 3A 20 22 73 65 74 6F 73 61 22 7D 2C]|timofeeva_iris|0        |7     |2022-08-29 12:29:03.858|0            |
|null|[20 20 7B 22 73 65 70 61 6C 4C 65 6E 67 74 68 22 3A 20 35 2E 30 2C 20 22 73 65 70 61 6C 57 69 64 74 68 22 3A 20 33 2E 34 2C 20 22 70 65 74 61 6C 4C 65 6E 67 74 68 22 3A 20 31 2E 35 2C 20 22 70 65 74 61 6C 57 69 64 74 68 22 3A 20 30 2E 32 2C 20 22 73 70 65 63 69 65 73 22 3A 20 22 73 65 74 6F 73 61 22 7D 2C]|timofeeva_iris|0        |8     |2022-08-29 12:29:03.858|0            |
|null|[20 20 7B 22 73 65 70 61 6C 4C 65 6E 67 74 68 22 3A 20 34 2E 34 2C 20 22 73 65 70 61 6C 57 69 64 74 68 22 3A 20 32 2E 39 2C 20 22 70 65 74 61 6C 4C 65 6E 67 74 68 22 3A 20 31 2E 34 2C 20 22 70 65 74 61 6C 57 69 64 74 68 22 3A 20 30 2E 32 2C 20 22 73 70 65 63 69 65 73 22 3A 20 22 73 65 74 6F 73 61 22 7D 2C]|timofeeva_iris|0        |9     |2022-08-29 12:29:03.858|0            |
+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------+------+-----------------------+-------------+


Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> out.stop()
>>> extended_iris = raw_data.select(F.from_json(F.col("value").cast("String"), schema).alias("value"), "offset").select("value.*", "offset").withColumn("receive_time", F.current_timestamp())
>>> def console_output(df, freq):
...     return df.writeStream \
...         .format("console") \
...         .trigger(processingTime='%s seconds' % freq ) \
...         .option("checkpointLocation", "checkpoints/duplicates_console_chk") \
...         .options(truncate=False) \
...         .start()
... 
>>> stream = console_output(extended_iris , 5)
>>> -------------------------------------------
Batch: 0
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |
+-----------+----------+-----------+----------+-------+------+-----------------------+
|null       |null      |null       |null      |null   |0     |2022-09-06 13:34:02.082|
|5.1        |3.5       |1.4        |0.2       |setosa |1     |2022-09-06 13:34:02.082|
|4.9        |3.0       |1.4        |0.2       |setosa |2     |2022-09-06 13:34:02.082|
|4.7        |3.2       |1.3        |0.2       |setosa |3     |2022-09-06 13:34:02.082|
|4.6        |3.1       |1.5        |0.2       |setosa |4     |2022-09-06 13:34:02.082|
+-----------+----------+-----------+----------+-------+------+-----------------------+

-------------------------------------------
Batch: 1
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |
+-----------+----------+-----------+----------+-------+------+-----------------------+
|5.0        |3.6       |1.4        |0.2       |setosa |5     |2022-09-06 13:34:02.576|
|5.4        |3.9       |1.7        |0.4       |setosa |6     |2022-09-06 13:34:02.576|
|4.6        |3.4       |1.4        |0.3       |setosa |7     |2022-09-06 13:34:02.576|
|5.0        |3.4       |1.5        |0.2       |setosa |8     |2022-09-06 13:34:02.576|
|4.4        |2.9       |1.4        |0.2       |setosa |9     |2022-09-06 13:34:02.576|
+-----------+----------+-----------+----------+-------+------+-----------------------+

-------------------------------------------
Batch: 2
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |
+-----------+----------+-----------+----------+-------+------+-----------------------+
|4.9        |3.1       |1.5        |0.1       |setosa |10    |2022-09-06 13:34:05.003|
|5.4        |3.7       |1.5        |0.2       |setosa |11    |2022-09-06 13:34:05.003|
|4.8        |3.4       |1.6        |0.2       |setosa |12    |2022-09-06 13:34:05.003|
|4.8        |3.0       |1.4        |0.1       |setosa |13    |2022-09-06 13:34:05.003|
|4.3        |3.0       |1.1        |0.1       |setosa |14    |2022-09-06 13:34:05.003|
+-----------+----------+-----------+----------+-------+------+-----------------------+

-------------------------------------------
Batch: 3
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |
+-----------+----------+-----------+----------+-------+------+-----------------------+
|5.8        |4.0       |1.2        |0.2       |setosa |15    |2022-09-06 13:34:10.002|
|5.7        |4.4       |1.5        |0.4       |setosa |16    |2022-09-06 13:34:10.002|
|5.4        |3.9       |1.3        |0.4       |setosa |17    |2022-09-06 13:34:10.002|
|5.1        |3.5       |1.4        |0.3       |setosa |18    |2022-09-06 13:34:10.002|
|5.7        |3.8       |1.7        |0.3       |setosa |19    |2022-09-06 13:34:10.002|
+-----------+----------+-----------+----------+-------+------+-----------------------+

-------------------------------------------
Batch: 4
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |
+-----------+----------+-----------+----------+-------+------+-----------------------+
|5.1        |3.8       |1.5        |0.3       |setosa |20    |2022-09-06 13:34:15.002|
|5.4        |3.4       |1.7        |0.2       |setosa |21    |2022-09-06 13:34:15.002|
|5.1        |3.7       |1.5        |0.4       |setosa |22    |2022-09-06 13:34:15.002|
|4.6        |3.6       |1.0        |0.2       |setosa |23    |2022-09-06 13:34:15.002|
|5.1        |3.3       |1.7        |0.5       |setosa |24    |2022-09-06 13:34:15.002|
+-----------+----------+-----------+----------+-------+------+-----------------------+


Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> stream.stop()
>>> waterwarked_iris = extended_iris.withWatermark("receive_time", "30 seconds")
>>> waterwarked_iris.printSchema()
root
 |-- sepalLength: float (nullable = true)
 |-- sepalWidth: float (nullable = true)
 |-- petalLength: float (nullable = true)
 |-- petalWidth: float (nullable = true)
 |-- species: string (nullable = true)
 |-- offset: long (nullable = true)
 |-- receive_time: timestamp (nullable = false)

>>> deduplicated_iris = waterwarked_iris.drop_duplicates(["species", "receive_time"])
>>> stream = console_output(deduplicated_iris , 20)
-------------------------------------------                                     
Batch: 0
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |
+-----------+----------+-----------+----------+-------+------+-----------------------+
|null       |null      |null       |null      |null   |0     |2022-09-06 13:37:35.632|
|5.1        |3.5       |1.4        |0.2       |setosa |1     |2022-09-06 13:37:35.632|
+-----------+----------+-----------+----------+-------+------+-----------------------+

-------------------------------------------                                     
Batch: 1
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |
+-----------+----------+-----------+----------+-------+------+-----------------------+
|5.0        |3.6       |1.4        |0.2       |setosa |5     |2022-09-06 13:37:40.003|
+-----------+----------+-----------+----------+-------+------+-----------------------+

-------------------------------------------                                     
Batch: 2
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |
+-----------+----------+-----------+----------+-------+------+-----------------------+
|4.9        |3.1       |1.5        |0.1       |setosa |10    |2022-09-06 13:38:00.002|
+-----------+----------+-----------+----------+-------+------+-----------------------+

[Stage 14:==========>                                            (39 + 4) / 200]
Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> 22/09/06 13:38:20 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2310)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:145)
	at net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:193)
	at java.io.FilterOutputStream.close(FilterOutputStream.java:159)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:417)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:287)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:132)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter$class.timeTakenMs(statefulOperators.scala:108)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec.timeTakenMs(statefulOperators.scala:429)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:117)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 13:38:20 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2310)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:145)
	at net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:193)
	at java.io.FilterOutputStream.close(FilterOutputStream.java:159)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:417)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:287)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:132)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter$class.timeTakenMs(statefulOperators.scala:108)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec.timeTakenMs(statefulOperators.scala:429)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:117)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 13:38:20 ERROR util.Utils: Aborting task
java.lang.IllegalStateException: Error committing version 4 into HDFSStateStore[id=(op=0,part=38),dir=hdfs://bigdataanalytics-head-0.mcs.local:8020/user/student1669_3/checkpoints/duplicates_console_chk/state/0/38]
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:138)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter$class.timeTakenMs(statefulOperators.scala:108)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec.timeTakenMs(statefulOperators.scala:429)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:117)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to shutdown streamer
	at org.apache.hadoop.hdfs.DFSOutputStream.closeThreads(DFSOutputStream.java:2214)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2278)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:145)
	at net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:193)
	at java.io.FilterOutputStream.close(FilterOutputStream.java:159)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:417)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:287)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:132)
	... 23 more
22/09/06 13:38:20 ERROR util.Utils: Aborting task
java.lang.IllegalStateException: Error committing version 4 into HDFSStateStore[id=(op=0,part=37),dir=hdfs://bigdataanalytics-head-0.mcs.local:8020/user/student1669_3/checkpoints/duplicates_console_chk/state/0/37]
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:138)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter$class.timeTakenMs(statefulOperators.scala:108)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec.timeTakenMs(statefulOperators.scala:429)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:117)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to shutdown streamer
	at org.apache.hadoop.hdfs.DFSOutputStream.closeThreads(DFSOutputStream.java:2214)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2278)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:145)
	at net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:193)
	at java.io.FilterOutputStream.close(FilterOutputStream.java:159)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:417)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:287)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:132)
	... 23 more
22/09/06 13:38:20 ERROR v2.WriteToDataSourceV2Exec: Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@dce273a is aborting.
22/09/06 13:38:20 ERROR v2.WriteToDataSourceV2Exec: Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@dce273a aborted.
22/09/06 13:38:20 ERROR v2.DataWritingSparkTask: Aborting commit for partition 37 (task 648, attempt 0, stage 14.0)
22/09/06 13:38:20 ERROR v2.DataWritingSparkTask: Aborted commit for partition 37 (task 648, attempt 0, stage 14.0)
22/09/06 13:38:20 ERROR v2.DataWritingSparkTask: Aborting commit for partition 38 (task 649, attempt 0, stage 14.0)
22/09/06 13:38:20 ERROR v2.DataWritingSparkTask: Aborted commit for partition 38 (task 649, attempt 0, stage 14.0)
22/09/06 13:38:20 ERROR streaming.MicroBatchExecution: Query [id = 2a3cc265-3410-4ca9-bf4f-858baee11b76, runId = 0bfff3a1-f04a-42e9-bad7-b26863a02f6d] terminated with error
org.apache.spark.SparkException: Writing job aborted.
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.doExecute(WriteToDataSourceV2Exec.scala:92)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:136)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:132)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:160)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:157)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:132)
	at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:252)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:301)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3388)
	at org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2788)
	at org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2788)
	at org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)
	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2788)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$5$$anonfun$apply$19.apply(MicroBatchExecution.scala:551)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$5.apply(MicroBatchExecution.scala:546)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:351)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch(MicroBatchExecution.scala:545)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply$mcV$sp(MicroBatchExecution.scala:198)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:166)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:166)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:351)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1.apply$mcZ$sp(MicroBatchExecution.scala:166)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:160)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:281)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:193)
Caused by: org.apache.spark.SparkException: Job 20 cancelled as part of cancellation of all jobs
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1860)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply$mcVI$sp(DAGScheduler.scala:852)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:852)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:852)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:852)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2118)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.doExecute(WriteToDataSourceV2Exec.scala:64)
	... 35 more
22/09/06 13:38:20 ERROR util.Utils: Aborting task
org.apache.spark.executor.CommitDeniedException: Commit denied for partition 39 (task 650, attempt 0, stage 14.0)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:133)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 13:38:20 ERROR v2.DataWritingSparkTask: Aborting commit for partition 39 (task 650, attempt 0, stage 14.0)
22/09/06 13:38:20 ERROR v2.DataWritingSparkTask: Aborted commit for partition 39 (task 650, attempt 0, stage 14.0)
22/09/06 13:38:20 ERROR util.Utils: Aborting task
org.apache.spark.executor.CommitDeniedException: Commit denied for partition 42 (task 653, attempt 0, stage 14.0)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:133)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 13:38:20 ERROR v2.DataWritingSparkTask: Aborting commit for partition 42 (task 653, attempt 0, stage 14.0)
22/09/06 13:38:20 ERROR v2.DataWritingSparkTask: Aborted commit for partition 42 (task 653, attempt 0, stage 14.0)
22/09/06 13:38:20 WARN scheduler.TaskSetManager: Lost task 37.0 in stage 14.0 (TID 648, localhost, executor driver): TaskKilled (Stage cancelled)
22/09/06 13:38:20 WARN scheduler.TaskSetManager: Lost task 38.0 in stage 14.0 (TID 649, localhost, executor driver): TaskKilled (Stage cancelled)
22/09/06 13:38:20 WARN scheduler.TaskSetManager: Lost task 39.0 in stage 14.0 (TID 650, localhost, executor driver): TaskKilled (Stage cancelled)
22/09/06 13:38:20 WARN scheduler.TaskSetManager: Lost task 42.0 in stage 14.0 (TID 653, localhost, executor driver): TaskKilled (Stage cancelled)

Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> stream.stop()
>>> windowed_iris = extended_iris.withColumn("window_time", F.window(F.col("receive_time"), "1 minutes"))
>>> windowed_iris.printSchema()
root
 |-- sepalLength: float (nullable = true)
 |-- sepalWidth: float (nullable = true)
 |-- petalLength: float (nullable = true)
 |-- petalWidth: float (nullable = true)
 |-- species: string (nullable = true)
 |-- offset: long (nullable = true)
 |-- receive_time: timestamp (nullable = false)
 |-- window_time: struct (nullable = false)
 |    |-- start: timestamp (nullable = true)
 |    |-- end: timestamp (nullable = true)

>>> waterwarked_windowed_iris = windowed_iris.withWatermark("window_time", "1 minutes")
>>> deduplicated_windowed_iris = waterwarked_windowed_iris \
...     .drop_duplicates(["species", "window_time"])
>>> stream = console_output(deduplicated_windowed_iris , 5)
-------------------------------------------                                     
Batch: 0
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |window_time                               |
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+
|null       |null      |null       |null      |null   |0     |2022-09-06 13:43:22.244|[2022-09-06 13:43:00, 2022-09-06 13:44:00]|
|5.1        |3.5       |1.4        |0.2       |setosa |1     |2022-09-06 13:43:22.244|[2022-09-06 13:43:00, 2022-09-06 13:44:00]|
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+

-------------------------------------------                                     
Batch: 1
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+-----------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|window_time|
+-----------+----------+-----------+----------+-------+------+------------+-----------+
+-----------+----------+-----------+----------+-------+------+------------+-----------+

-------------------------------------------                                     
Batch: 2
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+-----------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|window_time|
+-----------+----------+-----------+----------+-------+------+------------+-----------+
+-----------+----------+-----------+----------+-------+------+------------+-----------+

-------------------------------------------                                     
Batch: 3
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+-----------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|window_time|
+-----------+----------+-----------+----------+-------+------+------------+-----------+
+-----------+----------+-----------+----------+-------+------+------------+-----------+

-------------------------------------------                                     
Batch: 4
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+-----------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|window_time|
+-----------+----------+-----------+----------+-------+------+------------+-----------+
+-----------+----------+-----------+----------+-------+------+------------+-----------+

-------------------------------------------                                     
Batch: 5
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+-----------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|window_time|
+-----------+----------+-----------+----------+-------+------+------------+-----------+
+-----------+----------+-----------+----------+-------+------+------------+-----------+

-------------------------------------------                                     
Batch: 6
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+-----------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|window_time|
+-----------+----------+-----------+----------+-------+------+------------+-----------+
+-----------+----------+-----------+----------+-------+------+------------+-----------+

-------------------------------------------                                     
Batch: 7
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+-----------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|window_time|
+-----------+----------+-----------+----------+-------+------+------------+-----------+
+-----------+----------+-----------+----------+-------+------+------------+-----------+

-------------------------------------------                                     
Batch: 8
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+-----------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|window_time|
+-----------+----------+-----------+----------+-------+------+------------+-----------+
+-----------+----------+-----------+----------+-------+------+------------+-----------+

-------------------------------------------                                     
Batch: 9
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |window_time                               |
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+
|5.1        |3.8       |1.9        |0.4       |setosa |45    |2022-09-06 13:44:00.003|[2022-09-06 13:44:00, 2022-09-06 13:45:00]|
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+

-------------------------------------------                                     
Batch: 10
-------------------------------------------
+-----------+----------+-----------+----------+----------+------+-----------------------+------------------------------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species   |offset|receive_time           |window_time                               |
+-----------+----------+-----------+----------+----------+------+-----------------------+------------------------------------------+
|7.0        |3.2       |4.7        |1.4       |versicolor|51    |2022-09-06 13:44:05.002|[2022-09-06 13:44:00, 2022-09-06 13:45:00]|
+-----------+----------+-----------+----------+----------+------+-----------------------+------------------------------------------+


Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> out.stop()
-------------------------------------------                                     
Batch: 11
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+-----------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|window_time|
+-----------+----------+-----------+----------+-------+------+------------+-----------+
+-----------+----------+-----------+----------+-------+------+------------+-----------+

-------------------------------------------                                     
Batch: 12
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+-----------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|window_time|
+-----------+----------+-----------+----------+-------+------+------------+-----------+
+-----------+----------+-----------+----------+-------+------+------------+-----------+

-------------------------------------------                                     
Batch: 13
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+-----------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|window_time|
+-----------+----------+-----------+----------+-------+------+------------+-----------+
+-----------+----------+-----------+----------+-------+------+------------+-----------+


Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
[Stage 44:=======================================>              (147 + 4) / 200]
22/09/06 13:44:26 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2310)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:145)
	at net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:193)
	at java.io.FilterOutputStream.close(FilterOutputStream.java:159)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:417)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:287)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:132)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter$class.timeTakenMs(statefulOperators.scala:108)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec.timeTakenMs(statefulOperators.scala:429)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:117)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 13:44:26 WARN scheduler.TaskSetManager: Lost task 169.0 in stage 44.0 (TID 3638, localhost, executor driver): TaskKilled (Stage cancelled)
22/09/06 13:44:26 ERROR util.Utils: Aborting task
java.lang.IllegalStateException: Error committing version 15 into HDFSStateStore[id=(op=0,part=168),dir=hdfs://bigdataanalytics-head-0.mcs.local:8020/user/student1669_3/checkpoints/duplicates_console_chk/state/0/168]
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:138)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter$class.timeTakenMs(statefulOperators.scala:108)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec.timeTakenMs(statefulOperators.scala:429)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:117)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to shutdown streamer
	at org.apache.hadoop.hdfs.DFSOutputStream.closeThreads(DFSOutputStream.java:2214)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2278)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:145)
	at net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:193)
	at java.io.FilterOutputStream.close(FilterOutputStream.java:159)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:417)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:287)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:132)
	... 23 more
22/09/06 13:44:26 ERROR util.Utils: Aborting task
java.lang.IllegalStateException: Error committing version 15 into HDFSStateStore[id=(op=0,part=167),dir=hdfs://bigdataanalytics-head-0.mcs.local:8020/user/student1669_3/checkpoints/duplicates_console_chk/state/0/167]
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:138)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$2.apply(statefulOperators.scala:483)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter$class.timeTakenMs(statefulOperators.scala:108)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec.timeTakenMs(statefulOperators.scala:429)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4.apply$mcV$sp(statefulOperators.scala:483)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:47)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:36)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:117)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to shutdown streamer
	at org.apache.hadoop.hdfs.DFSOutputStream.closeThreads(DFSOutputStream.java:2214)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2278)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:145)
	at net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:193)
	at java.io.FilterOutputStream.close(FilterOutputStream.java:159)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:417)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:287)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:132)
	... 23 more
22/09/06 13:44:26 ERROR v2.WriteToDataSourceV2Exec: Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@71f9aeee is aborting.
22/09/06 13:44:26 ERROR v2.WriteToDataSourceV2Exec: Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@71f9aeee aborted.
22/09/06 13:44:26 ERROR v2.DataWritingSparkTask: Aborting commit for partition 167 (task 3636, attempt 0, stage 44.0)
22/09/06 13:44:26 ERROR v2.DataWritingSparkTask: Aborting commit for partition 168 (task 3637, attempt 0, stage 44.0)
22/09/06 13:44:26 ERROR v2.DataWritingSparkTask: Aborted commit for partition 167 (task 3636, attempt 0, stage 44.0)
22/09/06 13:44:26 ERROR v2.DataWritingSparkTask: Aborted commit for partition 168 (task 3637, attempt 0, stage 44.0)
22/09/06 13:44:26 WARN scheduler.TaskSetManager: Lost task 167.0 in stage 44.0 (TID 3636, localhost, executor driver): TaskKilled (Stage cancelled)
22/09/06 13:44:26 WARN scheduler.TaskSetManager: Lost task 168.0 in stage 44.0 (TID 3637, localhost, executor driver): TaskKilled (Stage cancelled)
22/09/06 13:44:26 ERROR util.Utils: Aborting task
org.apache.spark.executor.CommitDeniedException: Commit denied for partition 129 (task 3598, attempt 0, stage 44.0)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:133)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
>>> 22/09/06 13:44:26 ERROR v2.DataWritingSparkTask: Aborting commit for partition 129 (task 3598, attempt 0, stage 44.0)
22/09/06 13:44:26 ERROR v2.DataWritingSparkTask: Aborted commit for partition 129 (task 3598, attempt 0, stage 44.0)
22/09/06 13:44:26 WARN scheduler.TaskSetManager: Lost task 129.0 in stage 44.0 (TID 3598, localhost, executor driver): TaskKilled (Stage cancelled)
stream.stop()
>>> stream.stop()
>>> sliding_iris = extended_iris.withColumn("sliding_time", F.window(F.col("receive_time"), "1 minute", "30 seconds"))
>>> waterwarked_sliding_iris = sliding_iris.withWatermark("sliding_time", "2 minutes")
>>> deduplicated_sliding_iris = waterwarked_sliding_iris.drop_duplicates(["species", "sliding_time"])
>>> deduplicated_sliding_iris.printSchema()
root
 |-- sepalLength: float (nullable = true)
 |-- sepalWidth: float (nullable = true)
 |-- petalLength: float (nullable = true)
 |-- petalWidth: float (nullable = true)
 |-- species: string (nullable = true)
 |-- offset: long (nullable = true)
 |-- receive_time: timestamp (nullable = false)
 |-- sliding_time: struct (nullable = true)
 |    |-- start: timestamp (nullable = true)
 |    |-- end: timestamp (nullable = true)

>>> stream = console_output(deduplicated_sliding_iris , 20)
-------------------------------------------                                     
Batch: 0
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |sliding_time                              |
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+
|null       |null      |null       |null      |null   |0     |2022-09-06 13:48:09.392|[2022-09-06 13:47:30, 2022-09-06 13:48:30]|
|5.1        |3.5       |1.4        |0.2       |setosa |1     |2022-09-06 13:48:09.392|[2022-09-06 13:48:00, 2022-09-06 13:49:00]|
|5.1        |3.5       |1.4        |0.2       |setosa |1     |2022-09-06 13:48:09.392|[2022-09-06 13:47:30, 2022-09-06 13:48:30]|
|null       |null      |null       |null      |null   |0     |2022-09-06 13:48:09.392|[2022-09-06 13:48:00, 2022-09-06 13:49:00]|
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+

-------------------------------------------                                     
Batch: 1
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|sliding_time|
+-----------+----------+-----------+----------+-------+------+------------+------------+
+-----------+----------+-----------+----------+-------+------+------------+------------+

-------------------------------------------                                     
Batch: 2
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |sliding_time                              |
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+
|4.9        |3.1       |1.5        |0.1       |setosa |10    |2022-09-06 13:48:40.002|[2022-09-06 13:48:30, 2022-09-06 13:49:30]|
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+

-------------------------------------------                                     
Batch: 3
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time           |sliding_time                              |
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+
|5.8        |4.0       |1.2        |0.2       |setosa |15    |2022-09-06 13:49:00.002|[2022-09-06 13:49:00, 2022-09-06 13:50:00]|
+-----------+----------+-----------+----------+-------+------+-----------------------+------------------------------------------+

-------------------------------------------                                     
Batch: 4
-------------------------------------------
+-----------+----------+-----------+----------+-------+------+------------+------------+
|sepalLength|sepalWidth|petalLength|petalWidth|species|offset|receive_time|sliding_time|
+-----------+----------+-----------+----------+-------+------+------------+------------+
+-----------+----------+-----------+----------+-------+------+------------+------------+


Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> stream.stop()
>>> def console_output(df, freq, out_mode):
...     return df.writeStream.format("console") \
...         .trigger(processingTime='%s seconds' % freq ) \
...         .options(truncate=False) \
...         .option("checkpointLocation", "checkpoints/watermark_console_chk2") \
...         .outputMode(out_mode) \
...         .start()
... 
>>> count_iris = waterwarked_windowed_iris.groupBy("window_time").count()
>>> stream = console_output(count_iris , 20, "update")
-------------------------------------------                                     
Batch: 0
-------------------------------------------
+------------------------------------------+-----+
|window_time                               |count|
+------------------------------------------+-----+
|[2022-09-06 13:57:00, 2022-09-06 13:58:00]|5    |
+------------------------------------------+-----+

-------------------------------------------                                     
Batch: 1
-------------------------------------------
+------------------------------------------+-----+
|window_time                               |count|
+------------------------------------------+-----+
|[2022-09-06 13:57:00, 2022-09-06 13:58:00]|10   |
+------------------------------------------+-----+

-------------------------------------------                                     
Batch: 2
-------------------------------------------
+------------------------------------------+-----+
|window_time                               |count|
+------------------------------------------+-----+
|[2022-09-06 13:57:00, 2022-09-06 13:58:00]|15   |
+------------------------------------------+-----+

-------------------------------------------                                     
Batch: 3
-------------------------------------------
+------------------------------------------+-----+
|window_time                               |count|
+------------------------------------------+-----+
|[2022-09-06 13:58:00, 2022-09-06 13:59:00]|5    |
+------------------------------------------+-----+


Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> stream.stop()
>>> stream = console_output(count_iris , 20, "complete")
>>> 22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:12 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[Stage 64:=============>                                         (49 + 4) / 200]22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[Stage 64:==================>                                    (66 + 4) / 200]22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[Stage 64:======================>                                (82 + 4) / 200]22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[Stage 64:==========================>                            (95 + 4) / 200]22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:13 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[Stage 64:=============================>                        (108 + 4) / 200]22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
stream = console_output(count_iris , 20, "complete")22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[Stage 64:==================================>                   (128 + 4) / 200]22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[Stage 64:======================================>               (143 + 4) / 200]22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[Stage 64:===========================================>          (161 + 4) / 200]22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[Stage 64:=============================================>        (168 + 4) / 200]22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:14 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[Stage 64:================================================>     (178 + 4) / 200]22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
22/09/06 13:59:15 WARN state.HDFSBackedStateStoreProvider: The state for version 4 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.

Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> 22/09/06 13:59:15 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeInternal(DFSOutputStream.java:577)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:573)
22/09/06 13:59:15 ERROR v2.WriteToDataSourceV2Exec: Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@1b02a27f is aborting.
22/09/06 13:59:15 ERROR v2.WriteToDataSourceV2Exec: Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@1b02a27f aborted.
22/09/06 13:59:15 WARN hdfs.BlockReaderFactory: I/O error constructing remote block reader.
java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:659)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3436)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:673)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at net.jpountz.lz4.LZ4BlockInputStream.readFully(LZ4BlockInputStream.java:269)
	at net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:191)
	at net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:142)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:435)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply$mcVJ$sp(HDFSBackedStateStoreProvider.scala:384)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply(HDFSBackedStateStoreProvider.scala:383)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply(HDFSBackedStateStoreProvider.scala:383)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6.apply(HDFSBackedStateStoreProvider.scala:383)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6.apply(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:204)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:379)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 13:59:15 WARN hdfs.DFSClient: Failed to connect to /10.0.0.6:50010 for block, add to deadNodes and continue. java.nio.channels.ClosedByInterruptException
java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:659)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3436)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:673)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at net.jpountz.lz4.LZ4BlockInputStream.readFully(LZ4BlockInputStream.java:269)
	at net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:191)
	at net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:142)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:435)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply$mcVJ$sp(HDFSBackedStateStoreProvider.scala:384)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply(HDFSBackedStateStoreProvider.scala:383)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply(HDFSBackedStateStoreProvider.scala:383)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6.apply(HDFSBackedStateStoreProvider.scala:383)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6.apply(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:204)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:379)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 13:59:15 WARN hdfs.BlockReaderFactory: I/O error constructing remote block reader.
java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:659)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3436)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:673)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at net.jpountz.lz4.LZ4BlockInputStream.readFully(LZ4BlockInputStream.java:269)
	at net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:191)
	at net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:142)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:435)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply$mcVJ$sp(HDFSBackedStateStoreProvider.scala:384)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply(HDFSBackedStateStoreProvider.scala:383)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply(HDFSBackedStateStoreProvider.scala:383)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6.apply(HDFSBackedStateStoreProvider.scala:383)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6.apply(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:204)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:379)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 13:59:15 WARN hdfs.DFSClient: Failed to connect to /10.0.0.21:50010 for block, add to deadNodes and continue. java.nio.channels.ClosedByInterruptException
java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:659)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3436)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:673)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at net.jpountz.lz4.LZ4BlockInputStream.readFully(LZ4BlockInputStream.java:269)
	at net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:191)
	at net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:142)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:435)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply$mcVJ$sp(HDFSBackedStateStoreProvider.scala:384)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply(HDFSBackedStateStoreProvider.scala:383)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply(HDFSBackedStateStoreProvider.scala:383)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6.apply(HDFSBackedStateStoreProvider.scala:383)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6.apply(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:204)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:379)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 13:59:15 WARN ipc.Client: interrupted waiting to send rpc request to server
java.lang.InterruptedException
	at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:404)
	at java.util.concurrent.FutureTask.get(FutureTask.java:191)
	at org.apache.hadoop.ipc.Client$Connection.sendRpcRequest(Client.java:1059)
	at org.apache.hadoop.ipc.Client.call(Client.java:1454)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy20.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:255)
	at sun.reflect.GeneratedMethodAccessor66.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy21.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1226)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1213)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1201)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:306)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:272)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:264)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1526)
	at org.apache.hadoop.fs.Hdfs.open(Hdfs.java:315)
	at org.apache.hadoop.fs.Hdfs.open(Hdfs.java:58)
	at org.apache.hadoop.fs.AbstractFileSystem.open(AbstractFileSystem.java:628)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:795)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:791)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.open(FileContext.java:797)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.open(CheckpointFileManager.scala:322)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:424)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply$mcVJ$sp(HDFSBackedStateStoreProvider.scala:384)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply(HDFSBackedStateStoreProvider.scala:383)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$1.apply(HDFSBackedStateStoreProvider.scala:383)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6.apply(HDFSBackedStateStoreProvider.scala:383)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6.apply(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:204)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:379)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 13:59:15 WARN hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 2893.826815864854 msec.
22/09/06 13:59:15 WARN scheduler.TaskSetManager: Lost task 189.0 in stage 64.0 (TID 5637, localhost, executor driver): TaskKilled (Stage cancelled)
22/09/06 13:59:15 WARN ipc.Client: interrupted waiting to send rpc request to server
java.lang.InterruptedException
	at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:404)
	at java.util.concurrent.FutureTask.get(FutureTask.java:191)
	at org.apache.hadoop.ipc.Client$Connection.sendRpcRequest(Client.java:1059)
	at org.apache.hadoop.ipc.Client.call(Client.java:1454)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy20.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:255)
	at sun.reflect.GeneratedMethodAccessor66.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy21.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1226)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1213)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1201)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:306)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:272)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:264)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1526)
	at org.apache.hadoop.fs.Hdfs.open(Hdfs.java:315)
	at org.apache.hadoop.fs.Hdfs.open(Hdfs.java:58)
	at org.apache.hadoop.fs.AbstractFileSystem.open(AbstractFileSystem.java:628)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:795)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:791)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.open(FileContext.java:797)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.open(CheckpointFileManager.scala:322)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$readSnapshotFile(HDFSBackedStateStoreProvider.scala:524)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$4.apply(HDFSBackedStateStoreProvider.scala:376)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6$$anonfun$apply$4.apply(HDFSBackedStateStoreProvider.scala:376)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6.apply(HDFSBackedStateStoreProvider.scala:376)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$$anonfun$6.apply(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:204)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:379)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 13:59:15 ERROR streaming.MicroBatchExecution: Query [id = 1a62a9f9-d739-4999-8310-b8ae8d571542, runId = b7cd7c8b-f9ad-4db4-b9e9-b8e131cc2e2f] terminated with error
org.apache.spark.SparkException: Writing job aborted.
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.doExecute(WriteToDataSourceV2Exec.scala:92)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:136)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:132)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:160)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:157)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:132)
	at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:252)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:301)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3388)
	at org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2788)
	at org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2788)
	at org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)
	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2788)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$5$$anonfun$apply$19.apply(MicroBatchExecution.scala:551)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$5.apply(MicroBatchExecution.scala:546)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:351)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch(MicroBatchExecution.scala:545)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply$mcV$sp(MicroBatchExecution.scala:198)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:166)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:166)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:351)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1.apply$mcZ$sp(MicroBatchExecution.scala:166)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:160)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:281)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:193)
Caused by: org.apache.spark.SparkException: Job 68 cancelled as part of cancellation of all jobs
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1860)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply$mcVI$sp(DAGScheduler.scala:852)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:852)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:852)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:852)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2118)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.doExecute(WriteToDataSourceV2Exec.scala:64)
	... 35 more
22/09/06 13:59:15 WARN scheduler.TaskSetManager: Lost task 191.0 in stage 64.0 (TID 5639, localhost, executor driver): TaskKilled (Stage cancelled)
22/09/06 13:59:15 WARN scheduler.TaskSetManager: Lost task 188.0 in stage 64.0 (TID 5636, localhost, executor driver): TaskKilled (Stage cancelled)
22/09/06 13:59:15 WARN scheduler.TaskSetManager: Lost task 190.0 in stage 64.0 (TID 5638, localhost, executor driver): TaskKilled (Stage cancelled)
stream = c = console_output(count_iris , 20, "update")
Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> stream.stop()
>>> stream = console_output(count_iris , 20, "complete")
-------------------------------------------                                     
Batch: 0
-------------------------------------------
+------------------------------------------+-----+
|window_time                               |count|
+------------------------------------------+-----+
|[2022-09-06 13:59:00, 2022-09-06 14:00:00]|5    |
+------------------------------------------+-----+

-------------------------------------------                                     
Batch: 1
-------------------------------------------
+------------------------------------------+-----+
|window_time                               |count|
+------------------------------------------+-----+
|[2022-09-06 14:00:00, 2022-09-06 14:01:00]|5    |
|[2022-09-06 13:59:00, 2022-09-06 14:00:00]|5    |
+------------------------------------------+-----+

-------------------------------------------                                     
Batch: 2
-------------------------------------------
+------------------------------------------+-----+
|window_time                               |count|
+------------------------------------------+-----+
|[2022-09-06 14:00:00, 2022-09-06 14:01:00]|10   |
|[2022-09-06 13:59:00, 2022-09-06 14:00:00]|5    |
+------------------------------------------+-----+

[Stage 72:====================================>                 (135 + 4) / 200]
Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> 22/09/06 14:00:41 ERROR util.Utils: Aborting task
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1326)
	at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:212)
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:222)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)
	at org.apache.spark.scheduler.OutputCommitCoordinator.canCommit(OutputCommitCoordinator.scala:103)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:123)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$$anonfun$run$3.apply(WriteToDataSourceV2Exec.scala:116)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:146)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:67)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$doExecute$2.apply(WriteToDataSourceV2Exec.scala:66)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 14:00:41 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeInternal(DFSOutputStream.java:577)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:573)
22/09/06 14:00:41 WARN ipc.Client: interrupted waiting to send rpc request to server
java.lang.InterruptedException
	at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:404)
	at java.util.concurrent.FutureTask.get(FutureTask.java:191)
	at org.apache.hadoop.ipc.Client$Connection.sendRpcRequest(Client.java:1059)
	at org.apache.hadoop.ipc.Client.call(Client.java:1454)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy20.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)
	at sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy21.complete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:145)
	at net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:193)
	at java.io.FilterOutputStream.close(FilterOutputStream.java:159)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:417)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:287)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:132)
	at org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:89)
	at org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anonfun$doExecute$3$$anonfun$apply$2.apply$mcV$sp(statefulOperators.scala:319)
	at org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anonfun$doExecute$3$$anonfun$apply$2.apply(statefulOperators.scala:319)
	at org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anonfun$doExecute$3$$anonfun$apply$2.apply(statefulOperators.scala:319)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:535)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter$class.timeTakenMs(statefulOperators.scala:108)
	at org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:277)
	at org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anonfun$doExecute$3.apply(statefulOperators.scala:318)
	at org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anonfun$doExecute$3.apply(statefulOperators.scala:300)
	at org.apache.spark.sql.execution.streaming.state.package$StateStoreOps$$anonfun$1.apply(package.scala:67)
	at org.apache.spark.sql.execution.streaming.state.package$StateStoreOps$$anonfun$1.apply(package.scala:62)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:92)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 14:00:41 ERROR v2.DataWritingSparkTask: Aborting commit for partition 139 (task 6383, attempt 0, stage 72.0)
22/09/06 14:00:41 ERROR v2.WriteToDataSourceV2Exec: Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6df1aa54 is aborting.
22/09/06 14:00:41 WARN ipc.Client: interrupted waiting to send rpc request to server
java.lang.InterruptedException
	at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:404)
	at java.util.concurrent.FutureTask.get(FutureTask.java:191)
	at org.apache.hadoop.ipc.Client$Connection.sendRpcRequest(Client.java:1059)
	at org.apache.hadoop.ipc.Client.call(Client.java:1454)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy20.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
	at sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy21.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1648)
	at org.apache.hadoop.hdfs.DFSClient.primitiveCreate(DFSClient.java:1750)
	at org.apache.hadoop.fs.Hdfs.createInternal(Hdfs.java:102)
	at org.apache.hadoop.fs.Hdfs.createInternal(Hdfs.java:58)
	at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:584)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:686)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:682)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.create(FileContext.java:688)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:311)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:133)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:136)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:318)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:95)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:95)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:96)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:96)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.abort(HDFSBackedStateStoreProvider.scala:150)
	at org.apache.spark.sql.execution.streaming.state.package$StateStoreOps$$anonfun$1$$anonfun$apply$1.apply(package.scala:65)
	at org.apache.spark.sql.execution.streaming.state.package$StateStoreOps$$anonfun$1$$anonfun$apply$1.apply(package.scala:64)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:133)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
22/09/06 14:00:41 ERROR v2.WriteToDataSourceV2Exec: Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@6df1aa54 aborted.
22/09/06 14:00:41 ERROR v2.DataWritingSparkTask: Aborted commit for partition 139 (task 6383, attempt 0, stage 72.0)
22/09/06 14:00:41 ERROR streaming.MicroBatchExecution: Query [id = e35fd4c1-56ad-4028-bd03-a14fe401932e, runId = 36071432-f725-4f01-8506-be2716fc9a93] terminated with error
org.apache.spark.SparkException: Writing job aborted.
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.doExecute(WriteToDataSourceV2Exec.scala:92)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:136)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:132)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:160)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:157)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:132)
	at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:252)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:301)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3388)
	at org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2788)
	at org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2788)
	at org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)
	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2788)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$5$$anonfun$apply$19.apply(MicroBatchExecution.scala:551)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$5.apply(MicroBatchExecution.scala:546)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:351)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch(MicroBatchExecution.scala:545)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply$mcV$sp(MicroBatchExecution.scala:198)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:166)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:166)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:351)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1.apply$mcZ$sp(MicroBatchExecution.scala:166)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:160)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:281)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:193)
Caused by: org.apache.spark.SparkException: Job 75 cancelled as part of cancellation of all jobs
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1860)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply$mcVI$sp(DAGScheduler.scala:852)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:852)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:852)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:852)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2118)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.doExecute(WriteToDataSourceV2Exec.scala:64)
	... 35 more
22/09/06 14:00:41 ERROR spark.TaskContextImpl: Error in TaskCompletionListener
java.io.IOException: java.lang.InterruptedException
	at org.apache.hadoop.ipc.Client.call(Client.java:1460)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy20.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
	at sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy21.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1648)
	at org.apache.hadoop.hdfs.DFSClient.primitiveCreate(DFSClient.java:1750)
	at org.apache.hadoop.fs.Hdfs.createInternal(Hdfs.java:102)
	at org.apache.hadoop.fs.Hdfs.createInternal(Hdfs.java:58)
	at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:584)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:686)
	at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:682)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.create(FileContext.java:688)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:311)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:133)
	at org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:136)
	at org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:318)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:95)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:95)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:96)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:96)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.abort(HDFSBackedStateStoreProvider.scala:150)
	at org.apache.spark.sql.execution.streaming.state.package$StateStoreOps$$anonfun$1$$anonfun$apply$1.apply(package.scala:65)
	at org.apache.spark.sql.execution.streaming.state.package$StateStoreOps$$anonfun$1$$anonfun$apply$1.apply(package.scala:64)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:133)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException
	at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:404)
	at java.util.concurrent.FutureTask.get(FutureTask.java:191)
	at org.apache.hadoop.ipc.Client$Connection.sendRpcRequest(Client.java:1059)
	at org.apache.hadoop.ipc.Client.call(Client.java:1454)
	... 46 more
22/09/06 14:00:41 WARN scheduler.TaskSetManager: Lost task 141.0 in stage 72.0 (TID 6385, localhost, executor driver): TaskKilled (Stage cancelled)
22/09/06 14:00:41 WARN scheduler.TaskSetManager: Lost task 142.0 in stage 72.0 (TID 6386, localhost, executor driver): TaskKilled (Stage cancelled)
22/09/06 14:00:41 WARN scheduler.TaskSetManager: Lost task 140.0 in stage 72.0 (TID 6384, localhost, executor driver): TaskKilled (Stage cancelled)
22/09/06 14:00:41 WARN scheduler.TaskSetManager: Lost task 139.0 in stage 72.0 (TID 6383, localhost, executor driver): TaskKilled (Stage cancelled)
stream.stop()
>>> stream.stop()
>>> static_df_schema = StructType() \
...     .add("species", StringType()) \
...     .add("description", StringType())
>>> static_df_data = (
...     ("setosa", "Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal."),
...     ("versicolor", "Iris versicolor is a flowering herbaceous perennial plant, growing 10-80 cm high. The well developed blue flower has 6 petals and sepals spread out nearly flat and have two forms."),
...     ("virginica", "Iris virginica is a perennial plant. The plant has 2 to 4 erect or arching, bright green, lance-shaped leaves that are flattened into one plane at the base.")
... )
>>> static_df = spark.createDataFrame(static_df_data, static_df_schema)
>>> static_df.show()
+----------+--------------------+                                               
|   species|         description|
+----------+--------------------+
|    setosa|Iris setosa has a...|
|versicolor|Iris versicolor i...|
| virginica|Iris virginica is...|
+----------+--------------------+

>>> static_joined = waterwarked_iris.join(static_df, "species", "left")
>>> static_joined.isStreaming
True
>>> static_joined.printSchema()
root
 |-- species: string (nullable = true)
 |-- sepalLength: float (nullable = true)
 |-- sepalWidth: float (nullable = true)
 |-- petalLength: float (nullable = true)
 |-- petalWidth: float (nullable = true)
 |-- offset: long (nullable = true)
 |-- receive_time: timestamp (nullable = false)
 |-- description: string (nullable = true)

>>> stream = console_output(static_joined , 20, "update")
>>> -------------------------------------------
Batch: 0
-------------------------------------------
+-------+-----------+----------+-----------+----------+------+-----------------------+---------------------------------------------------------------------------------------------------------------+
|species|sepalLength|sepalWidth|petalLength|petalWidth|offset|receive_time           |description                                                                                                    |
+-------+-----------+----------+-----------+----------+------+-----------------------+---------------------------------------------------------------------------------------------------------------+
|null   |null       |null      |null       |null      |0     |2022-09-06 14:06:39.697|null                                                                                                           |
|setosa |5.1        |3.5       |1.4        |0.2       |1     |2022-09-06 14:06:39.697|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
|setosa |4.9        |3.0       |1.4        |0.2       |2     |2022-09-06 14:06:39.697|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
|setosa |4.7        |3.2       |1.3        |0.2       |3     |2022-09-06 14:06:39.697|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
|setosa |4.6        |3.1       |1.5        |0.2       |4     |2022-09-06 14:06:39.697|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
+-------+-----------+----------+-----------+----------+------+-----------------------+---------------------------------------------------------------------------------------------------------------+

-------------------------------------------
Batch: 1
-------------------------------------------
+-------+-----------+----------+-----------+----------+------+-----------------------+---------------------------------------------------------------------------------------------------------------+
|species|sepalLength|sepalWidth|petalLength|petalWidth|offset|receive_time           |description                                                                                                    |
+-------+-----------+----------+-----------+----------+------+-----------------------+---------------------------------------------------------------------------------------------------------------+
|setosa |5.0        |3.6       |1.4        |0.2       |5     |2022-09-06 14:06:40.462|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
|setosa |5.4        |3.9       |1.7        |0.4       |6     |2022-09-06 14:06:40.462|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
|setosa |4.6        |3.4       |1.4        |0.3       |7     |2022-09-06 14:06:40.462|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
|setosa |5.0        |3.4       |1.5        |0.2       |8     |2022-09-06 14:06:40.462|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
|setosa |4.4        |2.9       |1.4        |0.2       |9     |2022-09-06 14:06:40.462|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
+-------+-----------+----------+-----------+----------+------+-----------------------+---------------------------------------------------------------------------------------------------------------+

-------------------------------------------
Batch: 2
-------------------------------------------
+-------+-----------+----------+-----------+----------+------+-----------------------+---------------------------------------------------------------------------------------------------------------+
|species|sepalLength|sepalWidth|petalLength|petalWidth|offset|receive_time           |description                                                                                                    |
+-------+-----------+----------+-----------+----------+------+-----------------------+---------------------------------------------------------------------------------------------------------------+
|setosa |4.9        |3.1       |1.5        |0.1       |10    |2022-09-06 14:07:00.002|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
|setosa |5.4        |3.7       |1.5        |0.2       |11    |2022-09-06 14:07:00.002|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
|setosa |4.8        |3.4       |1.6        |0.2       |12    |2022-09-06 14:07:00.002|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
|setosa |4.8        |3.0       |1.4        |0.1       |13    |2022-09-06 14:07:00.002|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
|setosa |4.3        |3.0       |1.1        |0.1       |14    |2022-09-06 14:07:00.002|Iris setosa has a deep violet blue flower. The sepals are deeply-veined dark purple with a yellow-white signal.|
+-------+-----------+----------+-----------+----------+------+-----------------------+---------------------------------------------------------------------------------------------------------------+


Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> stream.stop()
>>> raw_orders_items = spark.readStream. \
...     format("kafka"). \
...     option("kafka.bootstrap.servers", kafka_brokers). \
...     option("subscribe", "timofeeva_order_items"). \
...     option("startingOffsets", "earliest"). \
...     load()
>>> schema_orders_items = StructType() \
...     .add("order_id", StringType()) \
...     .add("order_item_id", StringType()) \
...     .add("product_id", StringType()) \
...     .add("seller_id", StringType()) \
...     .add("shipping_limit_date", StringType()) \
...     .add("price", StringType()) \
...     .add("freight_value", StringType())
>>> extended_orders_items = raw_orders_items \
...     .select(F.from_json(F.col("value").cast("String"), schema_orders_items).alias("value")) \
...     .select("value.*") \
...     .withColumn("order_items_receive_time", F.current_timestamp()) \
...     .withColumn("window_time",F.window(F.col("order_items_receive_time"),"2 minutes"))
>>> extended_orders_items.printSchema()
root
 |-- order_id: string (nullable = true)
 |-- order_item_id: string (nullable = true)
 |-- product_id: string (nullable = true)
 |-- seller_id: string (nullable = true)
 |-- shipping_limit_date: string (nullable = true)
 |-- price: string (nullable = true)
 |-- freight_value: string (nullable = true)
 |-- order_items_receive_time: timestamp (nullable = false)
 |-- window_time: struct (nullable = false)
 |    |-- start: timestamp (nullable = true)
 |    |-- end: timestamp (nullable = true)

>>> raw_orders = spark.readStream. \
...     format("kafka"). \
...     option("kafka.bootstrap.servers", kafka_brokers). \
...     option("subscribe", "timofeeva_orders_json"). \
...     option("maxOffsetsPerTrigger", "5"). \
...     option("startingOffsets", "earliest"). \
...     load()
>>> schema = StructType() \
...     .add("order_id", StringType()) \
...     .add("customer_id", StringType()) \
...     .add("order_status", StringType()) \
...     .add("order_purchase_timestamp", StringType()) \
...     .add("order_approved_at", StringType()) \
...     .add("order_delivered_carrier_date", StringType()) \
...     .add("order_delivered_customer_date", StringType()) \
...     .add("order_estimated_delivery_date", StringType())
>>> waterwarked_windowed_orders = raw_orders \
...     .select(F.from_json(F.col("value").cast("String"), schema).alias("value"), "offset") \
...     .select("value.order_id", "value.order_status", "value.order_purchase_timestamp") \
...     .withColumn("order_receive_time", F.current_timestamp()) \
...     .withColumn("window_time",F.window(F.col("order_receive_time"),"2 minutes")) \
...     .withWatermark("window_time", "2 minutes")
>>> waterwarked_windowed_orders.printSchema()
root
 |-- order_id: string (nullable = true)
 |-- order_status: string (nullable = true)
 |-- order_purchase_timestamp: string (nullable = true)
 |-- order_receive_time: timestamp (nullable = false)
 |-- window_time: struct (nullable = false)
 |    |-- start: timestamp (nullable = true)
 |    |-- end: timestamp (nullable = true)

>>> streams_joined = waterwarked_windowed_orders \
...     .join(extended_orders_items, ["order_id", "window_time"] , "inner") \
...     .select("order_id", "order_item_id", "product_id", "window_time")
>>> stream = console_output(streams_joined , 20, "append")
-------------------------------------------                                     
Batch: 0
-------------------------------------------
+--------------------------------+-------------+--------------------------------+------------------------------------------+
|order_id                        |order_item_id|product_id                      |window_time                               |
+--------------------------------+-------------+--------------------------------+------------------------------------------+
|e481f51cbdc54678b7cc49136f2d6af7|1            |87285b34884572647811a353c7ac498a|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|47770eb9100c2d0c44946d9cf07ec65d|1            |aa4383b373c6aca5d8797843e5594415|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|order_id                        |order_item_id|product_id                      |[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|949d5b44dbf5de918fe9c16f97b45f8a|1            |d0b61bfb1de832b15ba9d266ca96e5b0|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|53cdb2fc8bc7dce0b6741e2150273451|1            |595fac2a385ac33a80bd5114aec74eb8|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
+--------------------------------+-------------+--------------------------------+------------------------------------------+

-------------------------------------------                                     
Batch: 1
-------------------------------------------
+--------------------------------+-------------+--------------------------------+------------------------------------------+
|order_id                        |order_item_id|product_id                      |window_time                               |
+--------------------------------+-------------+--------------------------------+------------------------------------------+
|6514b8ad8028c9f2cc2374ded245783f|1            |4520766ec412348b8d4caa5e8a18c464|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|76c6e866289321a7c93b82b54852dc33|1            |ac1789e492dcd698c5c10b97a671243a|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|a4591c265e18cb1dcee52889e2d8acc3|1            |060cb19345d90064d1015407193c233d|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|136cce7faa42fdb2cefd53fdc79a6098|1            |a1804276d9941ac0733cfd409f5206eb|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|ad21c59c0840e6cb83a9ceb5573f8159|1            |65266b2da20d04dbe00c5c2d3bb7859e|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
+--------------------------------+-------------+--------------------------------+------------------------------------------+

-------------------------------------------                                     
Batch: 2
-------------------------------------------
+--------------------------------+-------------+--------------------------------+------------------------------------------+
|order_id                        |order_item_id|product_id                      |window_time                               |
+--------------------------------+-------------+--------------------------------+------------------------------------------+
|5ff96c15d0b717ac6ad1f3d77225a350|1            |10adb53d8faa890ca7c2f0cbcb68d777|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|34513ce0c4fab462a55830c0989c7edb|1            |f7e0fa615b386bc9a8b9eb52bc1fff76|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|e6ce16cb79ec1d90b1da9085a6118aeb|1            |08574b074924071f4e201e151b152b4e|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|e6ce16cb79ec1d90b1da9085a6118aeb|2            |08574b074924071f4e201e151b152b4e|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|e69bfb5eb88e0ed6a785585b27e16dbf|1            |9a78fb9862b10749a117f7fc3c31f051|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
|82566a660a982b15fb86e904c8d32918|1            |72a97c271b2e429974398f46b93ae530|[2022-09-06 16:38:00, 2022-09-06 16:40:00]|
+--------------------------------+-------------+--------------------------------+------------------------------------------+


Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> stream.stop()
>>> raw_orders = spark.readStream. \
...     format("kafka"). \
...     option("kafka.bootstrap.servers", kafka_brokers). \
...     option("subscribe", "timofeeva_orders_json"). \
...     option("maxOffsetsPerTrigger", "5"). \
...     option("startingOffsets", "earliest"). \
...     load()
>>> schema = StructType() \
...     .add("order_id", StringType()) \
...     .add("customer_id", StringType()) \
...     .add("order_status", StringType()) \
...     .add("order_purchase_timestamp", StringType()) \
...     .add("order_approved_at", StringType()) \
...     .add("order_delivered_carrier_date", StringType()) \
...     .add("order_delivered_customer_date", StringType()) \
...     .add("order_estimated_delivery_date", StringType())
>>> parsed_orders = raw_orders \
...     .select(F.from_json(F.col("value").cast("String"), schema).alias("value"), "offset") \
...     .select("value.*", "offset") 
>>> extended_orders = parsed_orders \
...     .withColumn("my_extra_column", F.round( F.rand() * 100 )) \
...     .withColumn("my_current_time", F.current_timestamp())
>>> def foreach_batch_sink(df, freq):
...     return  df \
...         .writeStream \
...         .foreachBatch(foreach_batch_function) \
...         .trigger(processingTime='%s seconds' % freq ) \
...         .start()
... def foreach_batch_function(df, epoch_id):
  File "<stdin>", line 7
    def foreach_batch_function(df, epoch_id):
      ^
SyntaxError: invalid syntax
>>>     print("starting epoch " + str(epoch_id) )
  File "<stdin>", line 1
    print("starting epoch " + str(epoch_id) )
    ^
IndentationError: unexpected indent
>>>     df.persist()
  File "<stdin>", line 1
    df.persist()
    ^
IndentationError: unexpected indent
>>>     df.filter(F.col("order_status") != "delivered") \
  File "<stdin>", line 1
    df.filter(F.col("order_status") != "delivered") \
    ^
IndentationError: unexpected indent
>>>         .select("order_id", "order_status") \
  File "<stdin>", line 1
    .select("order_id", "order_status") \
    ^
IndentationError: unexpected indent
>>>         .withColumn("reason", F.lit("too slow")) \
  File "<stdin>", line 1
    .withColumn("reason", F.lit("too slow")) \
    ^
IndentationError: unexpected indent
>>>         .show(truncate=False)
  File "<stdin>", line 1
    .show(truncate=False)
    ^
IndentationError: unexpected indent
>>>     df.filter(F.col("order_status")=="delivered") \
  File "<stdin>", line 1
    df.filter(F.col("order_status")=="delivered") \
    ^
IndentationError: unexpected indent
>>>         .select("order_status", "order_delivered_customer_date") \
  File "<stdin>", line 1
    .select("order_status", "order_delivered_customer_date") \
    ^
IndentationError: unexpected indent
>>>         .withColumn("delivery_time", F.lit("very fast delivery")) \
  File "<stdin>", line 1
    .withColumn("delivery_time", F.lit("very fast delivery")) \
    ^
IndentationError: unexpected indent
>>>         .show(truncate=False)
  File "<stdin>", line 1
    .show(truncate=False)
    ^
IndentationError: unexpected indent
>>>     df.unpersist()
  File "<stdin>", line 1
    df.unpersist()
    ^
IndentationError: unexpected indent
>>>     print("finishing epoch " + str(epoch_id))def foreach_batch_function(df, epoch_id):
  File "<stdin>", line 1
    print("finishing epoch " + str(epoch_id))def foreach_batch_function(df, epoch_id):
    ^
IndentationError: unexpected indent
>>>     print("starting epoch " + str(epoch_id) )
  File "<stdin>", line 1
    print("starting epoch " + str(epoch_id) )
    ^
IndentationError: unexpected indent
>>>     df.persist()
  File "<stdin>", line 1
    df.persist()
    ^
IndentationError: unexpected indent
>>>     df.filter(F.col("order_status") != "delivered") \
  File "<stdin>", line 1
    df.filter(F.col("order_status") != "delivered") \
    ^
IndentationError: unexpected indent
>>>         .select("order_id", "order_status") \
  File "<stdin>", line 1
    .select("order_id", "order_status") \
    ^
IndentationError: unexpected indent
>>>         .withColumn("reason", F.lit("too slow")) \
  File "<stdin>", line 1
    .withColumn("reason", F.lit("too slow")) \
    ^
IndentationError: unexpected indent
>>>         .show(truncate=False)
  File "<stdin>", line 1
    .show(truncate=False)
    ^
IndentationError: unexpected indent
>>>     df.filter(F.col("order_status")=="delivered") \
  File "<stdin>", line 1
    df.filter(F.col("order_status")=="delivered") \
    ^
IndentationError: unexpected indent
>>>         .select("order_status", "order_delivered_customer_date") \
  File "<stdin>", line 1
    .select("order_status", "order_delivered_customer_date") \
    ^
IndentationError: unexpected indent
>>>         .withColumn("delivery_time", F.lit("very fast delivery")) \
  File "<stdin>", line 1
    .withColumn("delivery_time", F.lit("very fast delivery")) \
    ^
IndentationError: unexpected indent
>>>         .show(truncate=False)
  File "<stdin>", line 1
    .show(truncate=False)
    ^
IndentationError: unexpected indent
>>>     df.unpersist()
  File "<stdin>", line 1
    df.unpersist()
    ^
IndentationError: unexpected indent
>>>     print("finishing epoch " + str(epoch_id))def foreach_batch_function(df, epoch_id):
Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> def foreach_batch_function(df, epoch_id):
...     print("starting epoch " + str(epoch_id) )
...     df.persist()
...     df.filter(F.col("order_status") != "delivered") \
...         .select("order_id", "order_status") \
...         .withColumn("reason", F.lit("too slow")) \
...         .show(truncate=False)
...     df.filter(F.col("order_status")=="delivered") \
...             .select("order_status", "order_delivered_customer_date") \
...         .withColumn("delivery_time", F.lit("very fast delivery")) \
...         .show(truncate=False)
...     df.unpersist()
...     print("finishing epoch " + str(epoch_id))
... 
>>> stream = foreach_batch_sink(extended_orders, 20)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'foreach_batch_sink' is not defined
>>> 
Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> def foreach_batch_sink(df, freq):
...     return  df \
...         .writeStream \
...         .foreachBatch(foreach_batch_function) \
...         .trigger(processingTime='%s seconds' % freq ) \
...         .start()
... 
>>> stream = foreach_batch_sink(extended_orders, 20)
>>> starting epoch 0
+--------+------------+------+
|order_id|order_status|reason|
+--------+------------+------+
+--------+------------+------+

+------------+-----------------------------+-------------+
|order_status|order_delivered_customer_date|delivery_time|
+------------+-----------------------------+-------------+
+------------+-----------------------------+-------------+

finishing epoch 0
starting epoch 1
+--------+------------+------+
|order_id|order_status|reason|
+--------+------------+------+
+--------+------------+------+

+------------+-----------------------------+-------------+
|order_status|order_delivered_customer_date|delivery_time|
+------------+-----------------------------+-------------+
+------------+-----------------------------+-------------+

finishing epoch 1

Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> stream.stop()
>>> def foreach_batch_function(df, epoch_id):
...     print("starting epoch " + str(epoch_id) )
...     df.persist()
...     df.filter(F.col("order_status") != "delivered") \
...         .select("order_id", "order_status") \
...         .withColumn("reason", F.lit("too slow")) \
...         .show(truncate=False)
...     df.filter(F.col("order_status")=="delivered") \
...         .select("order_status", "order_delivered_customer_date") \
...         .withColumn("delivery_time", F.lit("very fast delivery")) \
...         .show(truncate=False)
...     df.unpersist()
...     print("finishing epoch " + str(epoch_id))
... 
>>> stream = foreach_batch_sink(extended_orders, 20)
>>> starting epoch 0
+--------+------------+------+
|order_id|order_status|reason|
+--------+------------+------+
+--------+------------+------+

+------------+-----------------------------+-------------+
|order_status|order_delivered_customer_date|delivery_time|
+------------+-----------------------------+-------------+
+------------+-----------------------------+-------------+

finishing epoch 0
starting epoch 1
+--------+------------+------+
|order_id|order_status|reason|
+--------+------------+------+
+--------+------------+------+

+------------+-----------------------------+-------------+
|order_status|order_delivered_customer_date|delivery_time|
+------------+-----------------------------+-------------+
+------------+-----------------------------+-------------+

finishing epoch 1

Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> stream.stop()
>>> def foreach_batch_function(df, epoch_id):
...     print("starting epoch " + str(epoch_id) )
...     df.persist()
...     df.filter(F.col("order_status")!="delivered"). \
...         select("order_id", "order_status"). \
...         withColumn("reason", F.lit("too slow")). \
...         show(truncate=False)
...     df.filter(F.col("order_status")=="delivered"). \
...         select("order_status", "order_delivered_customer_date"). \
...         withColumn("delivery_time", F.lit("very fast delivery")). \
...         show(truncate=False)
...     df.unpersist()
...     print("finishing epoch " + str(epoch_id))
... 
>>> def foreach_batch_sink(df, freq):
...     return  df \
...         .writeStream \
...         .foreachBatch(foreach_batch_function) \
...         .trigger(processingTime='%s seconds' % freq ) \
...         .start()
... 
>>> stream = foreach_batch_sink(extended_orders,20)
>>> starting epoch 0
+--------+------------+------+
|order_id|order_status|reason|
+--------+------------+------+
+--------+------------+------+

+------------+-----------------------------+-------------+
|order_status|order_delivered_customer_date|delivery_time|
+------------+-----------------------------+-------------+
+------------+-----------------------------+-------------+

finishing epoch 0
stream.stop()starting epoch 1
+--------+------------+------+
|order_id|order_status|reason|
+--------+------------+------+
+--------+------------+------+

+------------+-----------------------------+-------------+
|order_status|order_delivered_customer_date|delivery_time|
+------------+-----------------------------+-------------+
+------------+-----------------------------+-------------+

finishing epoch 1

>>> stream.stop()
>>> def foreach_batch_function(df, epoch_id):
...     print("I DO START THE BATCH")
...     df.persist() #сохрянем в память для многократного фильтра
...     #получаем DF хороших доставок
...     good_job = df.filter(F.col("order_status")=="delivered"). \
...         select("order_status", "order_delivered_customer_date"). \
...         withColumn("delivery_time", F.lit("very fast delivery"))
...     #получаем DF плохих доставок
...     bad_job = df.filter(F.col("order_status")!="delivered"). \
...         select("order_id", "order_status"). \
...         withColumn("reason", F.lit("too slow"))
...     #сохраняем DF плохих доставок для многократных action
...     bad_job.persist()
...     print("start writing these bad jobs:")
...     bad_job.show()
...     bad_job.write.mode("append").parquet("my_bad_job") #записываем плохие доставки в папку на hdfs
...     print("Bad jobs written: " +  str(bad_job.count()))
...     bad_job.unpersist() #удаляем из памяти плохие доставки
...     good_job.persist() #сохраняем DF хороших доставок для многократных action
...     print("start writing these good jobs:")
...     good_job.show()
...     df.unpersist() #удаляем из памяти полный набор
...     print("start writing these good jobs:")
...     good_job.write.mode("append").parquet("my_good_job") #записываем хорошие доставки в папку на hdfs
...     print("Good jobs: written: " + str(good_job.count()))
...     good_job.unpersist() #удаляем из памяти хорошие доставки
...     print("I FINISHED THE BATCH")
... 
>>> stream = foreach_batch_sink(extended_orders,30)
>>> I DO START THE BATCH
start writing these bad jobs:
+--------+------------+------+
|order_id|order_status|reason|
+--------+------------+------+
+--------+------------+------+

Bad jobs written: 0
start writing these good jobs:
+------------+-----------------------------+-------------+
|order_status|order_delivered_customer_date|delivery_time|
+------------+-----------------------------+-------------+
+------------+-----------------------------+-------------+

start writing these good jobs:
Good jobs: written: 0
I FINISHED THE BATCH
I DO START THE BATCH
start writing these bad jobs:
+--------+------------+------+
|order_id|order_status|reason|
+--------+------------+------+
+--------+------------+------+

Bad jobs written: 0
start writing these good jobs:
+------------+-----------------------------+-------------+
|order_status|order_delivered_customer_date|delivery_time|
+------------+-----------------------------+-------------+
+------------+-----------------------------+-------------+

start writing these good jobs:
Good jobs: written: 0
I FINISHED THE BATCH
stream.stop()
>>> spark.read.parquet('my_bad_job').show(Truncate=False)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: show() got an unexpected keyword argument 'Truncate'
>>> spark.read.parquet('my_bad_job').show(truncate=False)
+--------+------------+------+
|order_id|order_status|reason|
+--------+------------+------+
+--------+------------+------+

>>> parsed_orders = raw_orders \
...     .select(F.from_json(F.col("value").cast("String"), schema).alias("value"), "offset") \
...     .select("value.*", "offset")
>>> extended_orders = parsed_orders \
...     .withColumn("my_extra_column", F.round( F.rand() * 100 ) ) \
...     .withColumn("my_current_time", F.current_timestamp())
>>> def foreach_batch_sink(df, freq):
...     return  df \
...         .writeStream \
...         .foreachBatch(foreach_batch_function) \
...         .trigger(processingTime='%s seconds' % freq ) \
...         .start()
... 
>>> def foreach_batch_function(df, epoch_id):
...     print("starting epoch " + str(epoch_id) )
...     df.persist()
...     df.filter(F.col("order_status")!="delivered"). \
...         select("order_id", "order_status"). \
...         withColumn("reason", F.lit("too slow")). \
...         show(truncate=False)
...     df.filter(F.col("order_status")=="delivered"). \
...         select("order_status", "order_delivered_customer_date"). \
...         withColumn("delivery_time", F.lit("very fast delivery")). \
...         show(truncate=False)
...     df.unpersist()
...     print("finishing epoch " + str(epoch_id))
... 
>>> stream = foreach_batch_sink(extended_orders,20)
>>> starting epoch 0
+--------+------------+------+
|order_id|order_status|reason|
+--------+------------+------+
+--------+------------+------+

+------------+-----------------------------+-------------+
|order_status|order_delivered_customer_date|delivery_time|
+------------+-----------------------------+-------------+
+------------+-----------------------------+-------------+

finishing epoch 0
stream.stop()
>>> stream.stop()
>>> stream = foreach_batch_sink(parsed_orders,20)
>>> starting epoch 0
+--------+------------+------+
|order_id|order_status|reason|
+--------+------------+------+
+--------+------------+------+

+------------+-----------------------------+-------------+
|order_status|order_delivered_customer_date|delivery_time|
+------------+-----------------------------+-------------+
+------------+-----------------------------+-------------+

finishing epoch 0

Traceback (most recent call last):
  File "/opt/spark-2.4.8/python/pyspark/context.py", line 270, in signal_handler
    raise KeyboardInterrupt()
KeyboardInterrupt
>>> stream.stop()
